<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">.lst-kix_fhlz9mqwgqhk-0>li:before{content:"\0025cf  "}.lst-kix_s0slo2gimlv6-5>li:before{content:"\0025a0  "}ul.lst-kix_u7fw837454br-7{list-style-type:none}ul.lst-kix_u7fw837454br-8{list-style-type:none}.lst-kix_u7fw837454br-0>li:before{content:"\0025cf  "}.lst-kix_fhlz9mqwgqhk-4>li:before{content:"\0025cb  "}.lst-kix_fhlz9mqwgqhk-5>li:before{content:"\0025a0  "}.lst-kix_s0slo2gimlv6-6>li:before{content:"\0025cf  "}.lst-kix_u7fw837454br-1>li:before{content:"\0025cb  "}.lst-kix_fhlz9mqwgqhk-1>li:before{content:"\0025cb  "}.lst-kix_s0slo2gimlv6-7>li:before{content:"\0025cb  "}.lst-kix_s0slo2gimlv6-8>li:before{content:"\0025a0  "}.lst-kix_fhlz9mqwgqhk-2>li:before{content:"\0025a0  "}.lst-kix_fhlz9mqwgqhk-3>li:before{content:"\0025cf  "}ul.lst-kix_s0slo2gimlv6-8{list-style-type:none}ul.lst-kix_s0slo2gimlv6-7{list-style-type:none}ul.lst-kix_u7fw837454br-5{list-style-type:none}ul.lst-kix_u7fw837454br-6{list-style-type:none}ul.lst-kix_u7fw837454br-3{list-style-type:none}ul.lst-kix_u7fw837454br-4{list-style-type:none}ul.lst-kix_u7fw837454br-1{list-style-type:none}ul.lst-kix_u7fw837454br-2{list-style-type:none}ul.lst-kix_u7fw837454br-0{list-style-type:none}.lst-kix_9r6kk76ezmc0-6>li:before{content:"\0025cf  "}.lst-kix_9r6kk76ezmc0-5>li:before{content:"\0025a0  "}.lst-kix_9r6kk76ezmc0-4>li:before{content:"\0025cb  "}ul.lst-kix_i6klf5bi6ddj-5{list-style-type:none}ul.lst-kix_i6klf5bi6ddj-6{list-style-type:none}ul.lst-kix_i6klf5bi6ddj-7{list-style-type:none}ul.lst-kix_i6klf5bi6ddj-8{list-style-type:none}.lst-kix_iy3taumu8h3n-6>li:before{content:"\0025cf  "}.lst-kix_iy3taumu8h3n-8>li:before{content:"\0025a0  "}.lst-kix_9r6kk76ezmc0-1>li:before{content:"\0025cb  "}.lst-kix_9r6kk76ezmc0-3>li:before{content:"\0025cf  "}ul.lst-kix_i6klf5bi6ddj-1{list-style-type:none}ul.lst-kix_i6klf5bi6ddj-2{list-style-type:none}ul.lst-kix_i6klf5bi6ddj-3{list-style-type:none}ul.lst-kix_i6klf5bi6ddj-4{list-style-type:none}.lst-kix_iy3taumu8h3n-5>li:before{content:"\0025a0  "}.lst-kix_9r6kk76ezmc0-2>li:before{content:"\0025a0  "}ul.lst-kix_i6klf5bi6ddj-0{list-style-type:none}.lst-kix_iy3taumu8h3n-2>li:before{content:"\0025a0  "}.lst-kix_iy3taumu8h3n-4>li:before{content:"\0025cb  "}.lst-kix_iy3taumu8h3n-3>li:before{content:"\0025cf  "}.lst-kix_9r6kk76ezmc0-0>li:before{content:"\0025cf  "}ul.lst-kix_lr5teb3u785r-8{list-style-type:none}ul.lst-kix_lr5teb3u785r-7{list-style-type:none}ul.lst-kix_iy3taumu8h3n-0{list-style-type:none}ul.lst-kix_iy3taumu8h3n-1{list-style-type:none}ul.lst-kix_lr5teb3u785r-4{list-style-type:none}ul.lst-kix_s0slo2gimlv6-0{list-style-type:none}ul.lst-kix_iy3taumu8h3n-2{list-style-type:none}ul.lst-kix_lr5teb3u785r-3{list-style-type:none}ul.lst-kix_iy3taumu8h3n-3{list-style-type:none}ul.lst-kix_lr5teb3u785r-6{list-style-type:none}ul.lst-kix_s0slo2gimlv6-2{list-style-type:none}ul.lst-kix_iy3taumu8h3n-4{list-style-type:none}ul.lst-kix_lr5teb3u785r-5{list-style-type:none}ul.lst-kix_s0slo2gimlv6-1{list-style-type:none}ul.lst-kix_iy3taumu8h3n-5{list-style-type:none}ul.lst-kix_lr5teb3u785r-0{list-style-type:none}ul.lst-kix_s0slo2gimlv6-4{list-style-type:none}ul.lst-kix_iy3taumu8h3n-6{list-style-type:none}ul.lst-kix_s0slo2gimlv6-3{list-style-type:none}ul.lst-kix_iy3taumu8h3n-7{list-style-type:none}ul.lst-kix_lr5teb3u785r-2{list-style-type:none}ul.lst-kix_s0slo2gimlv6-6{list-style-type:none}.lst-kix_iy3taumu8h3n-7>li:before{content:"\0025cb  "}ul.lst-kix_iy3taumu8h3n-8{list-style-type:none}ul.lst-kix_lr5teb3u785r-1{list-style-type:none}ul.lst-kix_s0slo2gimlv6-5{list-style-type:none}.lst-kix_i6klf5bi6ddj-3>li:before{content:"\0025cf  "}.lst-kix_i6klf5bi6ddj-2>li:before{content:"\0025a0  "}.lst-kix_i6klf5bi6ddj-4>li:before{content:"\0025cb  "}.lst-kix_i6klf5bi6ddj-0>li:before{content:"\0025cf  "}.lst-kix_i6klf5bi6ddj-8>li:before{content:"\0025a0  "}.lst-kix_i6klf5bi6ddj-1>li:before{content:"\0025cb  "}.lst-kix_s0slo2gimlv6-3>li:before{content:"\0025cf  "}.lst-kix_s0slo2gimlv6-4>li:before{content:"\0025cb  "}.lst-kix_iy3taumu8h3n-0>li:before{content:"\0025cf  "}.lst-kix_s0slo2gimlv6-2>li:before{content:"\0025a0  "}.lst-kix_iy3taumu8h3n-1>li:before{content:"\0025cb  "}.lst-kix_i6klf5bi6ddj-7>li:before{content:"\0025cb  "}.lst-kix_s0slo2gimlv6-0>li:before{content:"\0025cf  "}.lst-kix_i6klf5bi6ddj-6>li:before{content:"\0025cf  "}.lst-kix_i6klf5bi6ddj-5>li:before{content:"\0025a0  "}.lst-kix_s0slo2gimlv6-1>li:before{content:"\0025cb  "}ul.lst-kix_9r6kk76ezmc0-2{list-style-type:none}ul.lst-kix_9r6kk76ezmc0-3{list-style-type:none}ul.lst-kix_9r6kk76ezmc0-0{list-style-type:none}ul.lst-kix_9r6kk76ezmc0-1{list-style-type:none}ul.lst-kix_9r6kk76ezmc0-6{list-style-type:none}ul.lst-kix_9r6kk76ezmc0-7{list-style-type:none}ul.lst-kix_9r6kk76ezmc0-4{list-style-type:none}ul.lst-kix_9r6kk76ezmc0-5{list-style-type:none}ul.lst-kix_9r6kk76ezmc0-8{list-style-type:none}.lst-kix_lr5teb3u785r-1>li:before{content:"\0025cb  "}ul.lst-kix_fhlz9mqwgqhk-6{list-style-type:none}ul.lst-kix_fhlz9mqwgqhk-7{list-style-type:none}.lst-kix_lr5teb3u785r-0>li:before{content:"\0025cf  "}.lst-kix_lr5teb3u785r-2>li:before{content:"\0025a0  "}ul.lst-kix_fhlz9mqwgqhk-8{list-style-type:none}ul.lst-kix_fhlz9mqwgqhk-2{list-style-type:none}ul.lst-kix_fhlz9mqwgqhk-3{list-style-type:none}ul.lst-kix_fhlz9mqwgqhk-4{list-style-type:none}ul.lst-kix_fhlz9mqwgqhk-5{list-style-type:none}.lst-kix_lr5teb3u785r-5>li:before{content:"\0025a0  "}.lst-kix_lr5teb3u785r-4>li:before{content:"\0025cb  "}ul.lst-kix_fhlz9mqwgqhk-0{list-style-type:none}.lst-kix_9r6kk76ezmc0-7>li:before{content:"\0025cb  "}ul.lst-kix_fhlz9mqwgqhk-1{list-style-type:none}.lst-kix_lr5teb3u785r-3>li:before{content:"\0025cf  "}.lst-kix_9r6kk76ezmc0-8>li:before{content:"\0025a0  "}.lst-kix_u7fw837454br-8>li:before{content:"\0025a0  "}.lst-kix_u7fw837454br-5>li:before{content:"\0025a0  "}.lst-kix_u7fw837454br-4>li:before{content:"\0025cb  "}.lst-kix_fhlz9mqwgqhk-8>li:before{content:"\0025a0  "}.lst-kix_u7fw837454br-2>li:before{content:"\0025a0  "}.lst-kix_fhlz9mqwgqhk-6>li:before{content:"\0025cf  "}.lst-kix_fhlz9mqwgqhk-7>li:before{content:"\0025cb  "}li.li-bullet-0:before{margin-left:-18pt;white-space:nowrap;display:inline-block;min-width:18pt}.lst-kix_u7fw837454br-3>li:before{content:"\0025cf  "}.lst-kix_lr5teb3u785r-8>li:before{content:"\0025a0  "}.lst-kix_lr5teb3u785r-6>li:before{content:"\0025cf  "}.lst-kix_u7fw837454br-6>li:before{content:"\0025cf  "}.lst-kix_lr5teb3u785r-7>li:before{content:"\0025cb  "}.lst-kix_u7fw837454br-7>li:before{content:"\0025cb  "}ol{margin:0;padding:0}table td,table th{padding:0}.c0{border-right-style:solid;padding-top:2pt;border-top-width:1pt;border-bottom-color:#000000;border-right-width:1pt;padding-left:2pt;border-left-color:#000000;padding-bottom:2pt;line-height:1.15;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#efefef;margin-left:36pt;border-left-style:solid;border-bottom-width:1pt;border-top-color:#000000;border-bottom-style:solid;orphans:2;widows:2;text-align:left;padding-right:2pt}.c20{border-right-style:solid;padding-top:2pt;border-top-width:1pt;border-bottom-color:#000000;border-right-width:1pt;padding-left:2pt;border-left-color:#000000;padding-bottom:2pt;line-height:1.15;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#cccccc;border-left-style:solid;border-bottom-width:1pt;border-top-color:#000000;border-bottom-style:solid;orphans:2;widows:2;text-align:left;padding-right:2pt}.c24{border-right-style:solid;padding-top:2pt;border-top-width:1pt;border-bottom-color:#000000;border-right-width:1pt;padding-left:2pt;border-left-color:#000000;padding-bottom:2pt;line-height:1.15;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#d9d9d9;border-left-style:solid;border-bottom-width:1pt;border-top-color:#000000;border-bottom-style:solid;text-align:left;padding-right:2pt}.c9{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:186pt;border-top-color:#cccccc;border-bottom-style:solid}.c4{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:189.8pt;border-top-color:#cccccc;border-bottom-style:solid}.c26{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:187.5pt;border-top-color:#cccccc;border-bottom-style:solid}.c19{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:202.5pt;border-top-color:#cccccc;border-bottom-style:solid}.c13{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:75pt;border-top-color:#cccccc;border-bottom-style:solid}.c1{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:221.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c16{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:225.7pt;border-top-color:#000000;border-bottom-style:solid}.c8{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c30{color:#cccccc;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Arial";font-style:italic}.c11{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Arial";font-style:normal}.c6{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Arial";font-style:normal}.c29{color:#999999;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Arial";font-style:italic}.c18{padding-top:20pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c22{color:#b7b7b7;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Arial";font-style:italic}.c23{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Arial";font-style:italic}.c41{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:italic}.c21{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:20pt;font-family:"Arial";font-style:normal}.c3{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Arial";font-style:normal}.c2{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c37{color:#d9d9d9;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:9pt;font-family:"Arial";font-style:italic}.c39{padding-top:12pt;padding-bottom:6pt;line-height:1.0;page-break-after:avoid;text-align:left}.c34{font-weight:400;text-decoration:none;vertical-align:baseline;font-family:"Arial";font-style:normal}.c36{background-color:#ffffff;padding-top:0pt;padding-bottom:8pt;line-height:1.15;text-align:left}.c17{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c25{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:right}.c33{border-spacing:0;border-collapse:collapse;margin-right:auto}.c7{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c40{background-color:#ffffff;max-width:451.4pt;padding:72pt 72pt 72pt 72pt}.c12{orphans:2;widows:2;height:11pt}.c35{background-color:#ffffff;color:#24292e;font-size:12pt}.c31{margin-left:36pt;padding-left:0pt}.c28{orphans:2;widows:2}.c32{color:#333333;font-size:11.5pt}.c10{padding:0;margin:0}.c38{margin-left:72pt;padding-left:0pt}.c5{height:15.8pt}.c15{height:0pt}.c14{font-weight:700}.c27{height:11pt}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c40"><h1 class="c28 c39" id="h.2uto7gmrwnu0"><span class="c21">Identifying Fraud from Enron Emails</span></h1><hr><p class="c7 c12"><span class="c2"></span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c8">Ludovic Tramutola</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c14">First submission</span><span class="c2">&nbsp;: 26/02/2021</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c14">What&rsquo;s new :</span></p><ul class="c10 lst-kix_lr5teb3u785r-0 start"><li class="c7 c31 c28 li-bullet-0"><span>First release</span></li></ul><p class="c7 c12"><span class="c2"></span></p><h1 class="c18" id="h.wgdntjhbmijm"><span class="c21">Introduction</span></h1><hr><p class="c7 c12"><span class="c2"></span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c29">A critical part of machine learning is making sense of your analysis process and communicating it to others. The questions below will help us understand your decision-making process and allow us to give feedback on your project. Please answer each question; your answers should be about 1-2 paragraphs per question. If you find yourself writing much more than that, take a step back and see if you can simplify your response!</span></p><p class="c7 c12"><span class="c29"></span></p><p class="c7 c28"><span class="c29">Summarize for us the goal of this project and how machine learning is useful in trying to accomplish it. As part of your answer, give some background on the dataset and how it can be used to answer the project question.</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c36 c28"><span class="c32">The goal of this project is to determine who are the person of interest </span><span class="c32 c34">in the Enron Fraud case based on the provided data : financial and email.</span></p><p class="c28 c36"><span class="c34 c32">In 2000, Enron was one of the top company in the united states but in 2002, due to a fraud, the company bankrupted.</span></p><p class="c36 c28"><span class="c32">Today, we have the data, including the results of the investigation, to use machine learning in order to detect who can be related to the fraud.</span></p><p class="c7 c28"><span>I&rsquo;ll try to follow my analysis. Beginning in python, I know I can optimise the code, create functions instead of copy/paste. But when I get something working I prefer not to touch it.</span></p><h1 class="c18" id="h.ktb135sb09e8"><span class="c21">Data exploration</span></h1><hr><p class="c7 c12"><span class="c2"></span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c22">Data Exploration (related lesson: &quot;Datasets and Questions&quot;)</span></p><p class="c7 c28"><span class="c22">Student response addresses the most important characteristics of the dataset and uses these characteristics to inform their analysis. Important characteristics include:</span></p><p class="c7 c28"><span class="c22">&nbsp; &nbsp; total number of data points</span></p><p class="c7 c28"><span class="c22">&nbsp; &nbsp; allocation across classes (POI/non-POI)</span></p><p class="c7 c28"><span class="c22">&nbsp; &nbsp; number of features used</span></p><p class="c7 c28"><span class="c22">&nbsp; &nbsp; are there features with many missing values? etc.</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c2">At this stage, I get some of the characteristics of the dataset we have.</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c0"><span class="c14">Total People number</span><span class="c2">&nbsp;: &nbsp;146</span></p><p class="c0 c27"><span class="c2"></span></p><p class="c0"><span class="c14">Number of features</span><span class="c2">&nbsp;: &nbsp;21</span></p><p class="c0 c27"><span class="c2"></span></p><p class="c0"><span class="c14">features names</span><span class="c2">:</span></p><p class="c0"><span class="c2">[&#39;salary&#39;,</span></p><p class="c0"><span class="c2">&nbsp;&#39;to_messages&#39;,</span></p><p class="c0"><span class="c2">&nbsp;&#39;deferral_payments&#39;,</span></p><p class="c0"><span class="c2">&nbsp;&#39;total_payments&#39;,</span></p><p class="c0"><span class="c2">&nbsp;&#39;exercised_stock_options&#39;,</span></p><p class="c0"><span class="c2">&nbsp;&#39;bonus&#39;,</span></p><p class="c0"><span class="c2">&nbsp;&#39;restricted_stock&#39;,</span></p><p class="c0"><span class="c2">&nbsp;&#39;shared_receipt_with_poi&#39;,</span></p><p class="c0"><span class="c2">&nbsp;&#39;restricted_stock_deferred&#39;,</span></p><p class="c0"><span class="c2">&nbsp;&#39;total_stock_value&#39;,</span></p><p class="c0"><span class="c2">&nbsp;&#39;expenses&#39;,</span></p><p class="c0"><span class="c2">&nbsp;&#39;loan_advances&#39;,</span></p><p class="c0"><span class="c2">&nbsp;&#39;from_messages&#39;,</span></p><p class="c0"><span class="c2">&nbsp;&#39;other&#39;,</span></p><p class="c0"><span class="c2">&nbsp;&#39;from_this_person_to_poi&#39;,</span></p><p class="c0"><span class="c2">&nbsp;&#39;poi&#39;,</span></p><p class="c0"><span class="c2">&nbsp;&#39;director_fees&#39;,</span></p><p class="c0"><span class="c2">&nbsp;&#39;deferred_income&#39;,</span></p><p class="c0"><span class="c2">&nbsp;&#39;long_term_incentive&#39;,</span></p><p class="c0"><span class="c2">&nbsp;&#39;email_address&#39;,</span></p><p class="c0"><span class="c2">&nbsp;&#39;from_poi_to_this_person&#39;]</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c0"><span class="c14">POIs list</span><span class="c2">&nbsp;:</span></p><p class="c0"><span class="c2">----</span></p><p class="c0"><span class="c2">HANNON KEVIN P</span></p><p class="c0"><span class="c2">COLWELL WESLEY</span></p><p class="c0"><span class="c2">RIEKER PAULA H</span></p><p class="c0"><span class="c2">KOPPER MICHAEL J</span></p><p class="c0"><span class="c2">SHELBY REX</span></p><p class="c0"><span class="c2">DELAINEY DAVID W</span></p><p class="c0"><span class="c2">LAY KENNETH L</span></p><p class="c0"><span class="c2">BOWEN JR RAYMOND M</span></p><p class="c0"><span class="c2">BELDEN TIMOTHY N</span></p><p class="c0"><span class="c2">FASTOW ANDREW S</span></p><p class="c0"><span class="c2">CALGER CHRISTOPHER F</span></p><p class="c0"><span class="c2">RICE KENNETH D</span></p><p class="c0"><span class="c2">SKILLING JEFFREY K</span></p><p class="c0"><span class="c2">YEAGER F SCOTT</span></p><p class="c0"><span class="c2">HIRKO JOSEPH</span></p><p class="c0"><span class="c2">KOENIG MARK E</span></p><p class="c0"><span class="c2">CAUSEY RICHARD A</span></p><p class="c0"><span class="c2">GLISAN JR BEN F</span></p><p class="c0"><span class="c2">----</span></p><p class="c0"><span class="c14">Total POIs</span><span class="c2">&nbsp;: &nbsp;18</span></p><p class="c0"><span class="c2">----------</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c8">Here are the management of the NaN and Zero data in the dataset :</span></p><p class="c7 c12"><span class="c8"></span></p><p class="c7 c28"><span class="c2">At first, it seemed there was no NaN but in reality it was not a real NaN.</span></p><p class="c7 c28"><span class="c2">So I had to convert it, especially when I tried to use dataframe conversion and plotting.</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c41">(Also, I discovered later, I needed to convert negative values into absolute ones.)</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c0"><span class="c2">Value/Nan check :</span></p><p class="c0"><span class="c2">---------------</span></p><p class="c0"><span class="c2">---------------</span></p><p class="c0"><span class="c2">NaN conversion : done</span></p><p class="c0"><span class="c2">---------------</span></p><p class="c0"><span class="c2">---------------</span></p><p class="c0"><span class="c2">Value/Zero check :</span></p><p class="c0"><span class="c2">---------------</span></p><p class="c0"><span class="c2">Zero number for each feature:</span></p><p class="c0"><span class="c2">from_poi_to_this_person &nbsp;: &nbsp;12</span></p><p class="c0"><span class="c2">from_this_person_to_poi &nbsp;: &nbsp;20</span></p><p class="c0"><span class="c2">poi &nbsp;: &nbsp;128</span></p><p class="c0"><span class="c2">---------------</span></p><p class="c0"><span class="c2">Zero check : done</span></p><p class="c0"><span class="c2">---------------</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c2">Concerning the zero value, it makes sense for these three features :</span></p><ul class="c10 lst-kix_i6klf5bi6ddj-0 start"><li class="c7 c31 c28 li-bullet-0"><span class="c2">from_poi_to_this_person &nbsp;: &nbsp;12</span></li><li class="c7 c31 c28 li-bullet-0"><span class="c2">from_this_person_to_poi &nbsp;: &nbsp;20</span></li><li class="c7 c31 c28 li-bullet-0"><span class="c2">poi &nbsp;: &nbsp;128</span></li></ul><p class="c7 c12"><span class="c2"></span></p><p class="c7 c12"><span class="c2"></span></p><h1 class="c18" id="h.vec2idqyufq7"><span class="c21">Outliers management</span></h1><hr><p class="c7 c12"><span class="c2"></span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c30">Outlier Investigation (related lesson: &quot;Outliers&quot;)</span></p><p class="c7 c28"><span class="c30">Student response identifies outlier(s) in the financial data, and explains how they are removed or otherwise handled.</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c2">As part of the training, we got a lesson about outliers management dedicated to Enron database.</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c8">As in the lesson outlier detection :</span></p><a id="t.0bdcba334b46f9a49c8108c6611ba6fa531d72d9"></a><a id="t.0"></a><table class="c33"><tbody><tr class="c15"><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image6.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image8.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr><tr class="c15"><td class="c16" colspan="1" rowspan="1"><p class="c17"><span class="c2">We clearly see an outlier when checking Bonus vs Salary relationship </span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c17"><span class="c2">SPOIL : after analysis and outlier removal, we see a more consistent pack of data</span></p></td></tr></tbody></table><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c2">For sure it works, but it does not come from me, it was part of the lessons.</span></p><p class="c7 c28"><span class="c2">Also I tried several relationship between several data, to me it was too much about luck than a real analysis, so I tried another one.</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c8">I tried to apply the InterQuartileRange IQR analysis manually :</span></p><p class="c7 c28"><span class="c2">Beginning in python, it is always several hours step by step to compile data into one table.</span></p><p class="c7 c28"><span>So, before going further into the kind of work, I took two features and check what I got with the IQR calculation.</span></p><p class="c0"><span class="c6">---------------</span></p><p class="c0"><span class="c6">IQR salary</span></p><p class="c0"><span class="c6">---------------</span></p><p class="c0 c27"><span class="c6"></span></p><p class="c0"><span class="c6">salary &nbsp;to_messages &nbsp;deferral_payments &nbsp;total_payments &nbsp;exercised_stock_options</span></p><p class="c0"><span class="c6">TOTAL &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;26704229.0 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;NaN &nbsp; &nbsp; &nbsp; &nbsp; 32083396.0 &nbsp; &nbsp; 309886585.0</span></p><p class="c0"><span class="c6">SKILLING JEFFREY K &nbsp; &nbsp;1111258.0 &nbsp; &nbsp; &nbsp; 3627.0 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;NaN &nbsp; &nbsp; &nbsp; 8682716.0</span></p><p class="c0"><span class="c6">LAY KENNETH L &nbsp; &nbsp; &nbsp; &nbsp; 1072321.0 &nbsp; &nbsp; &nbsp; 4273.0 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 202911.0 &nbsp; &nbsp; 103559793.0</span></p><p class="c0"><span class="c6">FREVERT MARK A &nbsp; &nbsp; &nbsp; &nbsp;1060932.0 &nbsp; &nbsp; &nbsp; 3275.0 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;6426990.0 &nbsp; &nbsp; &nbsp;17252530.0</span></p><p class="c0"><span class="c6">PICKERING MARK R &nbsp; &nbsp; &nbsp; 655037.0 &nbsp; &nbsp; &nbsp; &nbsp;898.0 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;NaN &nbsp; &nbsp; &nbsp; 1386690.0</span></p><p class="c0"><span class="c6">WHALLEY LAWRENCE G &nbsp; &nbsp; 510364.0 &nbsp; &nbsp; &nbsp; 6019.0 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;NaN &nbsp; &nbsp; &nbsp; 4677574.0</span></p><p class="c0"><span class="c6">DERRICK JR. JAMES V &nbsp; &nbsp;492375.0 &nbsp; &nbsp; &nbsp; 2181.0 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;NaN &nbsp; &nbsp; &nbsp; &nbsp;550981.0</span></p><p class="c0"><span class="c6">FASTOW ANDREW S &nbsp; &nbsp; &nbsp; &nbsp;440698.0 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;NaN &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;NaN &nbsp; &nbsp; &nbsp; 2424083.0</span></p><p class="c0"><span class="c6">SHERRIFF JOHN R &nbsp; &nbsp; &nbsp; &nbsp;428780.0 &nbsp; &nbsp; &nbsp; 3187.0 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;NaN &nbsp; &nbsp; &nbsp; 4335388.0</span></p><p class="c0"><span class="c6">RICE KENNETH D &nbsp; &nbsp; &nbsp; &nbsp; 420636.0 &nbsp; &nbsp; &nbsp; &nbsp;905.0 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;NaN &nbsp; &nbsp; &nbsp; &nbsp;505050.0</span></p><p class="c0 c27"><span class="c6"></span></p><p class="c0"><span class="c6">[10 rows x 21 columns]</span></p><p class="c0"><span class="c6">(95, 21)</span></p><p class="c0 c27"><span class="c6"></span></p><p class="c0"><span class="c6">---------------</span></p><p class="c0 c27"><span class="c6"></span></p><p class="c0"><span class="c6">---------------</span></p><p class="c0"><span class="c6">IQR to_messages</span></p><p class="c0"><span class="c6">---------------</span></p><p class="c0 c27"><span class="c6"></span></p><p class="c0"><span class="c6">salary &nbsp;to_messages &nbsp;deferral_payments &nbsp;total_payments &nbsp;exercised_stock_options</span></p><p class="c0"><span class="c6">SHAPIRO RICHARD S &nbsp; &nbsp; 269076.0 &nbsp; &nbsp; &nbsp;15149.0 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;NaN &nbsp; &nbsp; &nbsp; 1057548.0</span></p><p class="c0"><span class="c6">KEAN STEVEN J &nbsp; &nbsp; &nbsp; &nbsp; 404338.0 &nbsp; &nbsp; &nbsp;12754.0 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;NaN &nbsp; &nbsp; &nbsp; 1747522.0</span></p><p class="c0"><span class="c6">KITCHEN LOUISE &nbsp; &nbsp; &nbsp; &nbsp;271442.0 &nbsp; &nbsp; &nbsp; 8305.0 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;NaN &nbsp; &nbsp; &nbsp; 3471141.0</span></p><p class="c0"><span class="c6">BELDEN TIMOTHY N &nbsp; &nbsp; &nbsp;213999.0 &nbsp; &nbsp; &nbsp; 7991.0 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;2144013.0 &nbsp; &nbsp; &nbsp; 5501630.0</span></p><p class="c0"><span class="c6">BECK SALLY W &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;231330.0 &nbsp; &nbsp; &nbsp; 7315.0 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;NaN &nbsp; &nbsp; &nbsp; &nbsp;969068.0</span></p><p class="c0"><span class="c6">LAVORATO JOHN J &nbsp; &nbsp; &nbsp; 339288.0 &nbsp; &nbsp; &nbsp; 7259.0 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;NaN &nbsp; &nbsp; &nbsp;10425757.0</span></p><p class="c0"><span class="c6">WHALLEY LAWRENCE G &nbsp; &nbsp;510364.0 &nbsp; &nbsp; &nbsp; 6019.0 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;NaN &nbsp; &nbsp; &nbsp; 4677574.0</span></p><p class="c0"><span class="c6">KAMINSKI WINCENTY J &nbsp; 275101.0 &nbsp; &nbsp; &nbsp; 4607.0 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;NaN &nbsp; &nbsp; &nbsp; 1086821.0</span></p><p class="c0"><span class="c6">LAY KENNETH L &nbsp; &nbsp; &nbsp; &nbsp;1072321.0 &nbsp; &nbsp; &nbsp; 4273.0 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 202911.0 &nbsp; &nbsp; 103559793.0</span></p><p class="c0"><span class="c6">HAEDICKE MARK E &nbsp; &nbsp; &nbsp; 374125.0 &nbsp; &nbsp; &nbsp; 4009.0 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;2157527.0 &nbsp; &nbsp; &nbsp; 3859065.0</span></p><p class="c0 c27"><span class="c6"></span></p><p class="c0"><span class="c6">[10 rows x 21 columns]</span></p><p class="c0"><span class="c6">(86, 21)</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c2">For sure, I can exploit them but I understood this method should be an automatic one used in huge dataset.</span></p><p class="c7 c28"><span class="c2">So I tried another method to detect the outliers.</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c8">Visual boxplot(IQR) method :</span></p><p class="c7 c28"><span class="c2">Looking for outliers management into google, I saw the visual IQR boxplot method !</span></p><p class="c7 c28"><span class="c2">This one seemed really interesting and full of sense to me.</span></p><p class="c7 c28"><span class="c2">During my first try, I noticed, I should check who is the max outlier.</span></p><p class="c7 c28"><span class="c2">So I put the ID of the person who&rsquo;s outlying most.</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c2">As I saw the boxplot, I decided to not analyse the lower outliers, to me it was not relevant.</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c2">I decided to managed the outliers detecting who&rsquo;s the most outlying, analysing it, dropping it if necessary and checking again.</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c2">Analysing the outlier highlighted by the boxplot is depending of :</span></p><ul class="c10 lst-kix_s0slo2gimlv6-0 start"><li class="c7 c31 c28 li-bullet-0"><span class="c2">What is inside the data source, PDF file</span></li></ul><ul class="c10 lst-kix_s0slo2gimlv6-1 start"><li class="c7 c28 c38 li-bullet-0"><span class="c2">If it an error of the retrieving of the data</span></li></ul><ul class="c10 lst-kix_s0slo2gimlv6-0"><li class="c7 c31 c28 li-bullet-0"><span class="c2">If the person is a POI or not</span></li></ul><ul class="c10 lst-kix_s0slo2gimlv6-1 start"><li class="c7 c28 c38 li-bullet-0"><span class="c2">A POI may be an outlier </span></li></ul><p class="c7 c12"><span class="c2"></span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c2">Here is the result before and after :</span></p><a id="t.13f409bc61eb205f09c4a1eed191d9ceb7525545"></a><a id="t.1"></a><table class="c33"><tbody><tr class="c15"><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image24.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image27.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr><tr class="c15"><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image28.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image18.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr><tr class="c15"><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image14.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image9.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr><tr class="c15"><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image10.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image21.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr><tr class="c15"><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image13.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image29.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr><tr class="c15"><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image4.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image7.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr><tr class="c15"><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image5.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image5.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr><tr class="c15"><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image2.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image2.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr><tr class="c15"><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image16.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image16.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr><tr class="c15"><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image1.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image34.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr><tr class="c15"><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image20.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image12.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr><tr class="c15"><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image32.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image3.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr><tr class="c15"><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image23.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image17.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr><tr class="c15"><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image25.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image15.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr><tr class="c15"><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image35.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image33.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr><tr class="c15"><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image31.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image31.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr><tr class="c15"><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image26.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image26.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr><tr class="c15"><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image30.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image19.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr><tr class="c15"><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image11.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c17"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 286.00px; height: 214.67px;"><img alt="" src="images/image22.png" style="width: 286.00px; height: 214.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></td></tr><tr class="c15"><td class="c16" colspan="1" rowspan="1"><p class="c17 c27"><span class="c2"></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c17 c27"><span class="c2"></span></p></td></tr></tbody></table><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c2">In the end of this outliers analysis, I dropped :</span></p><p class="c7 c28"><span class="c2">&lsquo;TOTAL&rsquo; which is the total of the columns of the different features.</span></p><p class="c7 c28"><span class="c2">And I also saw during the check of the boxplot &#39;THE TRAVEL AGENCY IN THE PARK&#39; which is not a person although linked to a person.</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c2">I was thinking, the more relevant data we have, the best performance in term of quality we&rsquo;ll have to classify them. If I understood well, we check for error visualizing disparity of the data.</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c12"><span class="c2"></span></p><h1 class="c18" id="h.18gsp7gtjbw2"><span class="c21">Features management</span></h1><hr><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c37">What features did you end up using in your POI identifier, and what selection process did you use to pick them? Did you have to do any scaling? Why or why not? As part of the assignment, you should attempt to engineer your own feature that does not come ready-made in the dataset -- explain what feature you tried to make, and the rationale behind it. (You do not necessarily have to use it in the final analysis, only engineer and test it.) In your feature selection step, if you used an algorithm like a decision tree, please also give the feature importances of the features that you use, and if you used an automated feature selection function like SelectKBest, please report the feature scores and reasons for your choice of parameter values. &nbsp;[relevant rubric items: &ldquo;create new features&rdquo;, &ldquo;intelligently select features&rdquo;, &ldquo;properly scale features&rdquo;]</span></p><p class="c7 c12"><span class="c37"></span></p><p class="c7 c28"><span class="c2">The first thing concerning the features was to identify which data may be in relation with the fraud.</span></p><p class="c7 c28"><span class="c2">So, it is not about computer science but really about real life.</span></p><p class="c7 c28"><span class="c2">The scope of the data we have is financial and some relation between people with their mail.</span></p><p class="c7 c28"><span class="c2">As the goal of a fraud is about money, I suppose money data is pretty important.</span></p><p class="c7 c28"><span class="c2">In a company, the most used communication channel is the email.</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c2">So, I added 5 features calculated by already known features :</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span>In the order of </span><span>relevance </span><span class="c2">in my mind :</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c14">[&#39;ratio_to_poi&#39;]</span><span class="c2">&nbsp;= Percentage of mail sent to POI</span></p><p class="c7 c28"><span class="c14">[&#39;ratio_from_poi&#39;]</span><span class="c2">&nbsp;= Percentage of mail received from POI</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c14">[&#39;total_mail&#39;]</span><span class="c2">&nbsp;= total mail of a person</span></p><p class="c7 c28"><span class="c14">[&#39;total_mail_poi&#39;]</span><span class="c2">&nbsp;= Number of mail related to POI (sent and received)</span></p><p class="c7 c28"><span class="c14">[&#39;total_ratio_mail_poi&#39;]</span><span class="c2">&nbsp;= percentage of mail related to POI (sent and received)</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c2">I did not feel any need of scaling at this step.</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span>Then, I decided to use </span><span>scikit-learn </span><span>Univariate feature selection &ldquo;</span><span class="c14">selectKBest</span><span class="c2">&rdquo;.</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c2">My goal was to confront my vision to the computer vision, I found a code on google, displaying the result in a table :</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c8">Warning : Spoil : these results are bad !</span></p><a id="t.774273f9e21d93819e9a471b7d4d5f98b8a35836"></a><a id="t.2"></a><table class="c33"><tbody><tr class="c5"><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c3">feature</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c7"><span class="c3">score</span></p></td></tr><tr class="c5"><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c3">total_mail</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c7"><span class="c3">25.097542</span></p></td></tr><tr class="c5"><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c3">bonus</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c7"><span class="c3">24.464726</span></p></td></tr><tr class="c5"><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c3">director_fees</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c7"><span class="c3">21.060002</span></p></td></tr><tr class="c5"><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c3">restricted_stock</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c7"><span class="c3">18.575703</span></p></td></tr><tr class="c5"><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c3">from_poi_to_this_person</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c7"><span class="c3">16.641707</span></p></td></tr><tr class="c5"><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c3">expenses</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c7"><span class="c3">11.595548</span></p></td></tr><tr class="c5"><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c3">deferred_income</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c7"><span class="c3">10.072455</span></p></td></tr><tr class="c5"><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c3">from_this_person_to_poi</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c7"><span class="c3">8.961784</span></p></td></tr><tr class="c5"><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c3">salary</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c7"><span class="c3">8.866722</span></p></td></tr><tr class="c5"><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c3">restricted_stock_deferred</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c7"><span class="c3">8.746486</span></p></td></tr><tr class="c5"><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c3">shared_receipt_with_poi</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c7"><span class="c3">7.242730</span></p></td></tr><tr class="c5"><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c3">deferral_payments</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c7"><span class="c3">6.234201</span></p></td></tr><tr class="c5"><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c3">ratio_from_poi</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c7"><span class="c3">5.518506</span></p></td></tr><tr class="c5"><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c3">total_stock_value</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c7"><span class="c3">5.344942</span></p></td></tr><tr class="c5"><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c3">exercised_stock_options</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c7"><span class="c3">4.955198</span></p></td></tr><tr class="c5"><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c3">from_messages</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c7"><span class="c3">4.204971</span></p></td></tr><tr class="c5"><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c3">total_mail_poi</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c7"><span class="c3">3.210762</span></p></td></tr><tr class="c5"><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c3">ratio_to_poi</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c7"><span class="c3">2.426508</span></p></td></tr><tr class="c5"><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c3">other</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c7"><span class="c3">2.107656</span></p></td></tr><tr class="c5"><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c3">poi</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c7"><span class="c3">1.698824</span></p></td></tr><tr class="c5"><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c3">total_payments</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c7"><span class="c3">0.515192</span></p></td></tr><tr class="c5"><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c3">long_term_incentive</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c7"><span class="c3">0.245090</span></p></td></tr><tr class="c5"><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c3">to_messages</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c7"><span class="c3">0.225355</span></p></td></tr><tr class="c5"><td class="c4" colspan="1" rowspan="1"><p class="c7"><span class="c3">loan_advances</span></p></td><td class="c19" colspan="1" rowspan="1"><p class="c7"><span class="c3">0.164164</span></p></td></tr></tbody></table><p class="c7 c12"><span class="c2"></span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c2">After these first results, I tried the the classifiers as is to check how they perform :</span></p><p class="c12 c24"><span class="c2"></span></p><p class="c24 c28"><span class="c14">KNeighborsClassifier</span><span class="c2">(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,metric_params=None, n_jobs=1, n_neighbors=5, p=2,weights=&#39;uniform&#39;)</span></p><p class="c24 c28"><span class="c2">Precision: 0.04852</span></p><p class="c24 c28"><span class="c2">Recall: 0.01150</span></p><p class="c24 c12"><span class="c2"></span></p><p class="c24 c28"><span class="c14">GaussianNB</span><span class="c2">(priors=None)</span></p><p class="c24 c28"><span class="c2">Precision: 0.17341</span></p><p class="c24 c28"><span class="c2">Recall: 0.95100</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c2">The results were so bad, we wanted a precision and recall of 0.3 minimum.</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c2">I tried to select the features manually : selecting only a few and it worked, so I checked my selectKbest code and saw I should have removed POI from the display list, the label shifted&hellip;</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c8">With a better code, I used selectKbest again and got these good results :</span></p><p class="c7 c28"><span class="c8">in bold, the features I kept.</span></p><p class="c7 c12"><span class="c8"></span></p><a id="t.fb18c7a1be7ed8e323daff39368c01a82e681707"></a><a id="t.3"></a><table class="c33"><tbody><tr class="c5"><td class="c1" colspan="1" rowspan="1"><p class="c7"><span class="c11">features</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c7"><span class="c11">score</span></p></td></tr><tr class="c5"><td class="c1" colspan="1" rowspan="1"><p class="c7"><span class="c11">exercised_stock_options</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c7"><span class="c11">24.815080</span></p></td></tr><tr class="c5"><td class="c1" colspan="1" rowspan="1"><p class="c7"><span class="c11">total_stock_value</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c7"><span class="c11">24.179972</span></p></td></tr><tr class="c5"><td class="c1" colspan="1" rowspan="1"><p class="c7"><span class="c11">bonus</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c7"><span class="c11">20.792252</span></p></td></tr><tr class="c5"><td class="c1" colspan="1" rowspan="1"><p class="c7"><span class="c11">salary</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c7"><span class="c11">18.289684</span></p></td></tr><tr class="c5"><td class="c1" colspan="1" rowspan="1"><p class="c7"><span class="c11">ratio_to_poi</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c7"><span class="c11">16.409713</span></p></td></tr><tr class="c5"><td class="c1" colspan="1" rowspan="1"><p class="c7"><span class="c11">deferred_income</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c7"><span class="c11">11.458477</span></p></td></tr><tr class="c5"><td class="c1" colspan="1" rowspan="1"><p class="c7"><span class="c11">long_term_incentive</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c7"><span class="c11">9.922186</span></p></td></tr><tr class="c5"><td class="c1" colspan="1" rowspan="1"><p class="c7"><span class="c11">restricted_stock</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c7"><span class="c11">8.828679</span></p></td></tr><tr class="c5"><td class="c1" colspan="1" rowspan="1"><p class="c7"><span class="c11">total_payments</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c7"><span class="c11">8.772778</span></p></td></tr><tr class="c5"><td class="c1" colspan="1" rowspan="1"><p class="c7"><span class="c11">shared_receipt_with_poi</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c7"><span class="c11">8.589421</span></p></td></tr><tr class="c5"><td class="c1" colspan="1" rowspan="1"><p class="c7"><span class="c11">loan_advances</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c7"><span class="c11">7.184056</span></p></td></tr><tr class="c5"><td class="c1" colspan="1" rowspan="1"><p class="c7"><span class="c11">expenses</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c7"><span class="c11">6.094173</span></p></td></tr><tr class="c5"><td class="c1" colspan="1" rowspan="1"><p class="c7"><span class="c11">total_ratio_mail_poi</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c7"><span class="c11">5.399370</span></p></td></tr><tr class="c5"><td class="c1" colspan="1" rowspan="1"><p class="c7"><span class="c11">from_poi_to_this_person</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c7"><span class="c11">5.243450</span></p></td></tr><tr class="c5"><td class="c1" colspan="1" rowspan="1"><p class="c7"><span class="c23">total_mail_poi</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c7"><span class="c23">4.863682</span></p></td></tr><tr class="c5"><td class="c1" colspan="1" rowspan="1"><p class="c7"><span class="c23">other</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c7"><span class="c23">4.187478</span></p></td></tr><tr class="c5"><td class="c1" colspan="1" rowspan="1"><p class="c7"><span class="c23">ratio_from_poi</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c7"><span class="c23">3.128092</span></p></td></tr><tr class="c5"><td class="c1" colspan="1" rowspan="1"><p class="c7"><span class="c23">from_this_person_to_poi</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c7"><span class="c23">2.382612</span></p></td></tr><tr class="c5"><td class="c1" colspan="1" rowspan="1"><p class="c7"><span class="c23">director_fees</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c7"><span class="c23">2.126328</span></p></td></tr><tr class="c5"><td class="c1" colspan="1" rowspan="1"><p class="c7"><span class="c23">to_messages</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c7"><span class="c23">1.646341</span></p></td></tr><tr class="c5"><td class="c1" colspan="1" rowspan="1"><p class="c7"><span class="c23">total_mail</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c7"><span class="c23">0.490666</span></p></td></tr><tr class="c5"><td class="c1" colspan="1" rowspan="1"><p class="c7"><span class="c23">restricted_stock_deferred</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c7"><span class="c23">0.247053</span></p></td></tr><tr class="c5"><td class="c1" colspan="1" rowspan="1"><p class="c7"><span class="c23">deferral_payments</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c7"><span class="c23">0.233091</span></p></td></tr><tr class="c5"><td class="c1" colspan="1" rowspan="1"><p class="c7"><span class="c23">from_messages</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c7"><span class="c23">0.169701</span></p></td></tr></tbody></table><p class="c7 c12"><span class="c8"></span></p><p class="c7 c12"><span class="c8"></span></p><p class="c7 c28"><span class="c2">Time to check how well these new parameters performed :</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c20"><span class="c14">GaussianNB</span><span class="c2">(priors=None)</span></p><p class="c20"><span class="c2">Precision: 0.32480</span></p><p class="c20"><span class="c2">Recall: 0.31100</span></p><p class="c20 c27"><span class="c2"></span></p><p class="c20"><span class="c14">KNeighborsClassifier</span><span class="c2">(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;, metric_params=None, n_jobs=1, n_neighbors=5, p=2, weights=&#39;uniform&#39;)</span></p><p class="c20"><span class="c2">Precision: 0.63878</span></p><p class="c20"><span class="c2">Recall: 0.16800</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c8">I already reach the wanted results with Naive Bayes algorithm with my features selection :</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c12"><span class="c2"></span></p><p class="c20"><span class="c2">My features list will be :</span></p><p class="c20 c27"><span class="c2"></span></p><p class="c20"><span class="c2">[&#39;poi&#39;,</span></p><p class="c20"><span class="c2">&nbsp;&#39;exercised_stock_options&#39;,</span></p><p class="c20"><span class="c2">&nbsp;&#39;total_stock_value&#39;,</span></p><p class="c20"><span class="c2">&nbsp;&#39;bonus&#39;,</span></p><p class="c20"><span class="c2">&nbsp;&#39;salary&#39;,</span></p><p class="c20"><span class="c2">&nbsp;&#39;ratio_to_poi&#39;,</span></p><p class="c20"><span class="c2">&nbsp;&#39;deferred_income&#39;,</span></p><p class="c20"><span class="c2">&nbsp;&#39;long_term_incentive&#39;,</span></p><p class="c20"><span class="c2">&nbsp;&#39;restricted_stock&#39;,</span></p><p class="c20"><span class="c2">&nbsp;&#39;total_payments&#39;,</span></p><p class="c20"><span class="c2">&nbsp;&#39;shared_receipt_with_poi&#39;,</span></p><p class="c20"><span class="c2">&nbsp;&#39;loan_advances&#39;,</span></p><p class="c20"><span class="c2">&nbsp;&#39;expenses&#39;,</span></p><p class="c20"><span class="c2">&nbsp;&#39;total_ratio_mail_poi&#39;,</span></p><p class="c20"><span class="c2">&nbsp;&#39;from_poi_to_this_person&#39;]</span></p><p class="c20 c27"><span class="c2"></span></p><p class="c20"><span class="c2">end of features list</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c12"><span class="c2"></span></p><h1 class="c18" id="h.9qj0l3il1fg0"><span class="c21">Algorithm benchmarking</span></h1><hr><p class="c7 c12"><span class="c2"></span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c30">&nbsp;What algorithm did you end up using? What other one(s) did you try? How did model performance differ between algorithms? &nbsp;[relevant rubric item: &ldquo;pick an algorithm&rdquo;]</span></p><p class="c7 c12"><span class="c30"></span></p><p class="c7 c28"><span class="c30">&nbsp; &nbsp; What does it mean to tune the parameters of an algorithm, and what can happen if you don&rsquo;t do this well? &nbsp;How did you tune the parameters of your particular algorithm? What parameters did you tune? (Some algorithms do not have parameters that you need to tune -- if this is the case for the one you picked, identify and briefly explain how you would have done it for the model that was not your final choice or a different model that does utilize parameter tuning, e.g. a decision tree classifier). &nbsp;[relevant rubric items: &ldquo;discuss parameter tuning&rdquo;, &ldquo;tune the algorithm&rdquo;]</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c2">At first I used these 2 algorithms as they are the ones I understood really well during the lessons, also, Naive Bayes doesn&rsquo;t require any hyper-parameters.</span></p><ul class="c10 lst-kix_iy3taumu8h3n-0 start"><li class="c7 c31 c28 li-bullet-0"><span class="c2">GaussianNB</span></li><li class="c7 c28 c31 li-bullet-0"><span class="c2">KNeighborsClassifier</span></li></ul><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span>The first thing I can say is : </span><span class="c8">the feature selection is part of the parameters.</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c2">Although I got the desired score, I decided to check more algorithms and also I&rsquo;ll train myself to use scikit learn.</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c2">My second step was to launch with default hyper-parameters the following algorithms using the test_classifier() function provided :</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c20"><span class="c14">GaussianNB</span><span class="c2">(priors=None)</span></p><p class="c20"><span>Accuracy: 0.82193 &nbsp; &nbsp; &nbsp; </span><span class="c14">Precision: 0.32480 </span><span>&nbsp; &nbsp; &nbsp;</span><span class="c14">Recall: 0.31100</span><span class="c2">&nbsp;F1: 0.31775 &nbsp; &nbsp; F2: 0.31367</span></p><p class="c20"><span class="c2">Total predictions: 15000 &nbsp; &nbsp; &nbsp; &nbsp;True positives: &nbsp;622 &nbsp; &nbsp;False positives: 1293 &nbsp; False negatives: 1378 &nbsp; True negatives: 11707</span></p><p class="c20 c27"><span class="c2"></span></p><p class="c20"><span class="c2">KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;, metric_params=None, n_jobs=1, n_neighbors=5, p=2, weights=&#39;uniform&#39;)</span></p><p class="c20"><span>Accuracy: 0.87640 &nbsp; &nbsp; &nbsp;</span><span class="c14">&nbsp;Precision: 0.63878</span><span class="c2">&nbsp; &nbsp; &nbsp; Recall: 0.16800 F1: 0.26603 &nbsp; &nbsp; F2: 0.19704</span></p><p class="c20"><span class="c2">Total predictions: 15000 &nbsp; &nbsp; &nbsp; &nbsp;True positives: &nbsp;336 &nbsp; &nbsp;False positives: &nbsp;190 &nbsp; False negatives: 1664 &nbsp; True negatives: 12810</span></p><p class="c20 c27"><span class="c2"></span></p><p class="c20"><span class="c2">LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,</span></p><p class="c20"><span class="c2">intercept_scaling=1, loss=&#39;squared_hinge&#39;, max_iter=1000,</span></p><p class="c20"><span class="c2">multi_class=&#39;ovr&#39;, penalty=&#39;l2&#39;, random_state=None, tol=0.0001,</span></p><p class="c20"><span class="c2">verbose=0)</span></p><p class="c20"><span class="c2">Accuracy: 0.68300 &nbsp; &nbsp; &nbsp; Precision: 0.13335 &nbsp; &nbsp; &nbsp;Recall: 0.25050 F1: 0.17405 &nbsp; &nbsp; F2: 0.21306</span></p><p class="c20"><span class="c2">Total predictions: 15000 &nbsp; &nbsp; &nbsp; &nbsp;True positives: &nbsp;501 &nbsp; &nbsp;False positives: 3256 &nbsp; False negatives: 1499 &nbsp; True negatives: 9744</span></p><p class="c20 c27"><span class="c2"></span></p><p class="c20"><span class="c2">LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,</span></p><p class="c20"><span class="c2">intercept_scaling=1, loss=&#39;hinge&#39;, max_iter=1000, multi_class=&#39;ovr&#39;,</span></p><p class="c20"><span class="c2">penalty=&#39;l2&#39;, random_state=None, tol=0.0001, verbose=0)</span></p><p class="c20"><span class="c2">Accuracy: 0.69147 &nbsp; &nbsp; &nbsp; Precision: 0.13090 &nbsp; &nbsp; &nbsp;Recall: 0.23300 F1: 0.16763 &nbsp; &nbsp; F2: 0.20156</span></p><p class="c20"><span class="c2">Total predictions: 15000 &nbsp; &nbsp; &nbsp; &nbsp;True positives: &nbsp;466 &nbsp; &nbsp;False positives: 3094 &nbsp; False negatives: 1534 &nbsp; True negatives: 9906</span></p><p class="c20 c27"><span class="c2"></span></p><p class="c20"><span class="c2">LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,intercept_scaling=1, loss=&#39;squared_hinge&#39;, max_iter=1000, multi_class=&#39;ovr&#39;, penalty=&#39;l2&#39;, random_state=None, tol=0.0001, verbose=0)</span></p><p class="c20"><span class="c2">Accuracy: 0.69073 &nbsp; &nbsp; &nbsp; Precision: 0.13070 &nbsp; &nbsp; &nbsp;Recall: 0.23350 F1: 0.16759 &nbsp; &nbsp; F2: 0.20176</span></p><p class="c20"><span class="c2">Total predictions: 15000 &nbsp; &nbsp; &nbsp; &nbsp;True positives: &nbsp;467 &nbsp; &nbsp;False positives: 3106 &nbsp; False negatives: 1533 &nbsp; True negatives: 9894</span></p><p class="c20 c27"><span class="c2"></span></p><p class="c20"><span class="c2">DecisionTreeClassifier(class_weight=None, criterion=&#39;gini&#39;, max_depth=None, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, presort=False, random_state=None, splitter=&#39;best&#39;)</span></p><p class="c20"><span class="c2">Accuracy: 0.81380 &nbsp; &nbsp; &nbsp; Precision: 0.29509 &nbsp; &nbsp; &nbsp;Recall: 0.28550 F1: 0.29022 &nbsp; &nbsp; F2: 0.28737</span></p><p class="c20"><span class="c2">Total predictions: 15000 &nbsp; &nbsp; &nbsp; &nbsp;True positives: &nbsp;571 &nbsp; &nbsp;False positives: 1364 &nbsp; False negatives: 1429 &nbsp; True negatives: 11636</span></p><p class="c20 c27"><span class="c2"></span></p><p class="c20"><span class="c2">AdaBoostClassifier(algorithm=&#39;SAMME.R&#39;, base_estimator=None, learning_rate=1.0, n_estimators=50, random_state=None)</span></p><p class="c20"><span>Accuracy: 0.83247 &nbsp; &nbsp; &nbsp; </span><span class="c14">Precision: 0.34293</span><span class="c2">&nbsp; &nbsp; &nbsp; Recall: 0.28000 F1: 0.30829 &nbsp; &nbsp; F2: 0.29067</span></p><p class="c20"><span class="c2">Total predictions: 15000 &nbsp; &nbsp; &nbsp; &nbsp;True positives: &nbsp;560 &nbsp; &nbsp;False positives: 1073 &nbsp; False negatives: 1440 &nbsp; True negatives: 11927</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c2">As previously, Naive Bayes performed well.</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span>I decided to go more in depth and tried to use </span><span class="c14">GridSearchCV </span><span>on </span><span class="c8">DecisionTreeClassifier</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c2">I use a parameters table mixing :</span></p><ul class="c10 lst-kix_u7fw837454br-0 start"><li class="c7 c31 c28 li-bullet-0"><span class="c2">&#39;max_features&#39;</span></li><li class="c7 c31 c28 li-bullet-0"><span class="c2">&#39;splitter&#39;</span></li><li class="c7 c31 c28 li-bullet-0"><span class="c2">&#39;criterion&#39;&#39;</span></li></ul><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c2">It ended the best parameters were :</span></p><ul class="c10 lst-kix_9r6kk76ezmc0-0 start"><li class="c7 c31 c28 li-bullet-0"><span class="c2">max_features= &#39;sqrt&#39;</span></li><li class="c7 c31 c28 li-bullet-0"><span class="c2">splitter= &#39;best&#39;</span></li><li class="c7 c31 c28 li-bullet-0"><span class="c2">criterion= &#39;gini&#39;</span></li></ul><p class="c7 c12"><span class="c2"></span></p><p class="c7 c12"><span class="c2"></span></p><p class="c20"><span class="c14">DecisionTreeClassifier</span><span class="c2">(class_weight=None, criterion=&#39;entropy&#39;, max_depth=None,</span></p><p class="c20"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; max_features=&#39;auto&#39;, max_leaf_nodes=None,</span></p><p class="c20"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; min_impurity_decrease=0.0, min_impurity_split=None,</span></p><p class="c20"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; min_samples_leaf=1, min_samples_split=2,</span></p><p class="c20"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; min_weight_fraction_leaf=0.0, presort=False, random_state=None,</span></p><p class="c20"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; splitter=&#39;best&#39;)</span></p><p class="c20"><span>&nbsp; &nbsp; &nbsp; &nbsp; Accuracy: 0.83553 &nbsp; &nbsp; &nbsp; </span><span class="c14">Precision: 0.37107</span><span>&nbsp; &nbsp; &nbsp; </span><span class="c14">Recall: 0.33600</span><span class="c2">&nbsp;F1: 0.35266 &nbsp; &nbsp; F2: 0.34247</span></p><p class="c20"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; Total predictions: 15000 &nbsp; &nbsp; &nbsp; &nbsp;True positives: &nbsp;672 &nbsp; &nbsp;False positives: 1139 &nbsp; False negatives: 1328 &nbsp; True negatives: 11861&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.561000108719 &nbsp;secs</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c2">These results are slightly better than Naive Bayes. I am sure if I spend more time and testing with different features, we can reach a better score.</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c12"><span class="c2"></span></p><h1 class="c18" id="h.jwrzz0svgpyl"><span class="c21">Validation</span></h1><hr><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c22">What is validation, and what&rsquo;s a classic mistake you can make if you do it wrong? How did you validate your analysis? &nbsp;[relevant rubric items: &ldquo;discuss validation&rdquo;, &ldquo;validation strategy&rdquo;]</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c2">Validation is the method you use to determine if the algorithm is well performing or not.</span></p><p class="c7 c28"><span class="c2">The classic mistake is to use the same data to train the algorithm and to test it.</span></p><p class="c7 c28"><span class="c2">In this case, we talk about overfitting.</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c2">In sci-kit learn, there are several validation tools.</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c2">As the provided code kindly includes the test_classifier() function using stratified shuffle split cross validation method, I did not use another one and stick with it.</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c12"><span class="c2"></span></p><h1 class="c18" id="h.vznjdir1rae3"><span class="c21">Metrics</span></h1><hr><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c22">&nbsp; &nbsp; Give at least 2 evaluation metrics and your average performance for each of them. &nbsp;Explain an interpretation of your metrics that says something human-understandable about your algorithm&rsquo;s performance. [relevant rubric item: &ldquo;usage of evaluation metrics&rdquo;]</span></p><p class="c7 c12"><span class="c22"></span></p><p class="c7 c28"><span class="c2">As the performance requested were :</span></p><ul class="c10 lst-kix_fhlz9mqwgqhk-0 start"><li class="c7 c31 c28 li-bullet-0"><span class="c2">Precision &gt;=0.3</span></li><li class="c7 c31 c28 li-bullet-0"><span>Recall &gt;=0.3</span></li></ul><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c2">I&rsquo;ll talk about these two.</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c2">About my performance :</span></p><p class="c7 c12"><span class="c8"></span></p><a id="t.b08499c9f46a5a378c89ff7979b5507d31225677"></a><a id="t.4"></a><table class="c33"><tbody><tr class="c5"><td class="c26" colspan="1" rowspan="1"><p class="c7 c27"><span class="c3"></span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c7"><span class="c14">Precision</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c7"><span class="c14">recall</span></p></td></tr><tr class="c5"><td class="c26" colspan="1" rowspan="1"><p class="c7"><span>GaussianNB</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c25"><span>0,3248</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c25"><span class="c14">0,311</span></p></td></tr><tr class="c5"><td class="c26" colspan="1" rowspan="1"><p class="c7"><span>KNeighborsClassifier</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c25"><span class="c14">0,63878</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c25"><span>0,168</span></p></td></tr><tr class="c5"><td class="c26" colspan="1" rowspan="1"><p class="c7"><span>LinearSVC(squared_hinge)</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c25"><span>0,13335</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c25"><span>0,2505</span></p></td></tr><tr class="c5"><td class="c26" colspan="1" rowspan="1"><p class="c7"><span>LinearSVC(hinge)</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c25"><span>0,1309</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c25"><span>0,233</span></p></td></tr><tr class="c5"><td class="c26" colspan="1" rowspan="1"><p class="c7"><span>LinearSVC</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c25"><span>0,1307</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c25"><span>0,2335</span></p></td></tr><tr class="c5"><td class="c26" colspan="1" rowspan="1"><p class="c7"><span>DecisionTreeClassifier</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c25"><span>0,29509</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c25"><span>0,2855</span></p></td></tr><tr class="c5"><td class="c26" colspan="1" rowspan="1"><p class="c7"><span>AdaBoostClassifier</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c25"><span>0,34293</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c25"><span>0,28</span></p></td></tr><tr class="c5"><td class="c26" colspan="1" rowspan="1"><p class="c7"><span class="c14">average</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c25"><span>0,29</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c25"><span>0,25</span></p></td></tr><tr class="c5"><td class="c26" colspan="1" rowspan="1"><p class="c7"><span class="c14">maximum</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c25"><span>0,64</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c25"><span>0,31</span></p></td></tr></tbody></table><p class="c7 c12"><span class="c8"></span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c2">About their meaning :</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c8">Precision is the algorithm performance to classify correctly.</span></p><p class="c7 c28"><span class="c2">In our case, the precision is the real POI detected divided by the right or wrong POI detected by the algorithm.</span></p><p class="c7 c28"><span class="c2">How many POI detected are true POI.</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c14">Recall is the algorithm capacity to detect correct data.</span></p><p class="c7 c28"><span class="c2">In our case, the recall is the number of real POI detected divided by the real number of POI.</span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c12"><span class="c2"></span></p><h1 class="c18" id="h.qmd4p2w8izew"><span class="c21">Conclusion</span></h1><hr><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c22">&nbsp; </span></p><p class="c7 c12"><span class="c2"></span></p><p class="c7 c28"><span class="c34 c35">Here is the algorithm I choose : simple and working</span></p><p class="c7 c12"><span class="c34 c35"></span></p><p class="c20"><span class="c14">GaussianNB</span><span class="c2">(priors=None)</span></p><p class="c20"><span>Accuracy: 0.82193 &nbsp; &nbsp; &nbsp; </span><span class="c14">Precision: 0.32480 </span><span>&nbsp; &nbsp; &nbsp;</span><span class="c14">Recall: 0.31100</span><span class="c2">&nbsp;F1: 0.31775 &nbsp; &nbsp; F2: 0.31367</span></p><p class="c20"><span>Total predictions: 15000 &nbsp; &nbsp; &nbsp; &nbsp;True positives: &nbsp;622 &nbsp; &nbsp;False positives: 1293 &nbsp; False negatives: 1378 &nbsp; True negatives: 11707</span></p><p class="c7 c12"><span class="c2"></span></p></body></html>